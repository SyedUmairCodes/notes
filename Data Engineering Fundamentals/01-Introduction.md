# Introduction to Data Engineering

Data engineering is the process of creating a pipeline or system of data where data is ingested after creation, cleaned and processed to be used by data analysts and scientists. It mainly involves data being stored in SQL databases and data warehouses like BigQuery.

Data engineers deal with huge amounts of data so distributed systems and "big data" tools like Apache Spark, Apache Hadoop, and others are used in the process as well.

The role of data engineers can be traced backed to 1980s when data warehousing was introduced right when relational databases and SQL were also being developed by IBM and Oracle.

>[!NOTE]
>When data systems began expanding,businesses recognized the need for specialized tools and data pipelines to facilitate reporting and business intelligence (BI). To address the challenge of accurately modeling business logic within these data warehouses.

> [!NOTE]
> Massively Parallel Processing (MPP) databases that could handle vast amounts of data simultaneously were used for scalable analytics and led to new roles like ETL and warehouse developers being created.