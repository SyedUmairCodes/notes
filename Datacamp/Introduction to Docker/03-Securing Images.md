Here's a structured and complete version of your Docker course notes, with added context and explanations.

## Docker: Building, Distributing, and Running Containers

This section provides a detailed guide on how to work with Docker, from basic container management to creating your own custom images and sharing them.

### 1. Running and Inspecting Containers

The **Docker Command Line Interface (CLI)** is your primary interface for sending instructions to the **Docker Daemon**, the background service that manages all Docker objects (images and containers).

#### Key Commands for Container Lifecycle:

*   **`docker run <image-name>`:** Starts a new container from the specified image.
    *   **Default Behavior:** By default, Docker runs the container and displays its output directly in your terminal. The container stops once its primary process finishes.
    *   **Example (`hello-world`):** `docker run hello-world` will print an introductory message and then stop, as designed by its creators.
    *   **Example (`ubuntu` without flags):** `docker run ubuntu` will start and immediately shut down because the `ubuntu` image's default `CMD` (which defines what runs when the container starts) is often set to something that exits quickly if not interactive.

*   **`docker run -it <image-name>` (Interactive Containers):** Use the `-it` flags to run a container in interactive mode and get a pseudo-TTY (terminal). This is essential for images designed for user interaction, like an operating system.
    *   **`-i`:** Keeps the standard input (stdin) open, even if not attached.
    *   **`-t`:** Allocates a pseudo-TTY, enabling an interactive shell.
    *   **Example:** `docker run -it ubuntu` will launch an Ubuntu container and provide you with a bash shell prompt inside it, allowing you to execute commands within the isolated Ubuntu environment.
    *   To exit the interactive session and stop the container, type `exit`.

*   **`docker run -d <image-name>` (Detached Containers):** Use the `-d` flag to run a container in "detached" mode, meaning it runs in the background. This is ideal for long-running services (e.g., databases, web servers) that don't need their output continuously displayed in your terminal.
    *   **`-d` (detached):** Runs the container in the background.
    *   **Example:** `docker run -d postgres` will start a PostgreSQL database server in the background. Its output (logs) will not clutter your terminal.

*   **`docker ps`** or **`docker container ls`:** Lists all currently running containers. This command is crucial for monitoring your active Docker environment. It displays information such as `CONTAINER ID`, `IMAGE`, `COMMAND`, `CREATED`, `STATUS`, `PORTS`, and `NAMES`.

*   **`docker stop <container-id | container-name>`:** Stops a running container. You can use either the unique container ID (from `docker ps`) or a custom name you assigned to stop it.

**Code Snippets:**

```bash
docker run hello-world                     # Run a hello-world container (prints output, then stops)
docker run -it ubuntu                      # Run an Ubuntu container interactively, get a shell
docker run -d postgres                     # Run a PostgreSQL container in the background (detached)
docker ps                                  # Show currently running containers
docker stop <container-id_or_name>         # Stop a running container
```

### 2. Streamlining Container Workflow

Efficiently managing containers becomes vital when working with numerous instances.

#### Naming Containers:

*   **`docker run --name <custom-name> <image-name>`:** Assigns a human-readable name to a container at creation. This name simplifies identification in `docker ps` output and can be used interchangeably with the Container ID for other Docker commands.
    *   **Example:** `docker run -d --name db_pipeline_v1 postgres`

#### Filtering Containers:

*   **`docker ps -f "name=<container_name>"`:** Filters the output of `docker ps` to display only containers matching specific criteria.
    *   **`-f` (filter):** Specifies a filter.
    *   **Example:** `docker ps -f "name=db_pipeline_v1"` will show only the container named `db_pipeline_v1`. Filters can be applied to other properties too (e.g., `status=exited`).

#### Viewing Container Logs:

*   **`docker logs <container-id | container-name>`:** Retrieves and displays the historical logs generated by a container. Useful for debugging issues after a container has run.
*   **`docker logs -f <container-id | container-name>` (Follow Logs):** "Follows" the logs, displaying new output in real-time as the container generates it. Press `Ctrl + C` to exit the live log view.

#### Removing Containers:

*   **`docker rm <container-id | container-name>`** or **`docker container rm <container-id | container-name>`:** Permanently removes a *stopped* container from your system, freeing up disk space and allowing its name to be reused.
    *   A stopped container still occupies disk space until removed.
*   **`docker container prune`:** A convenient command to remove all stopped (non-running) containers in one go, freeing up significant disk space.

**Code Snippets:**

```shell
docker run -d --name linux_sandbox ubuntu # Run a detached Ubuntu container and name it
docker ps -f "name=linux_sandbox"         # Filter running containers by name
docker logs linux_sandbox                 # Show the logs of the container
docker stop linux_sandbox                 # Stop the running container
docker rm linux_sandbox                   # Delete the stopped container
```

### 3. Sharing and Managing Docker Images

Images are fundamental to Docker. You'll either get them from registries or create your own.

#### Docker Registries:

*   **Docker Hub:** The official and most popular public registry for Docker images. It hosts thousands of pre-built images.
*   **Private Registries:** Organizations or individuals can host their own registries for private image storage and distribution. Images from private registries are identifiable by a URL prefix (e.g., `dockerhub.myprivateregistry.com/image:version`).

#### Pulling Images from Registries:

*   **`docker pull <image-name>`:** Downloads an image from Docker Hub (or a configured default registry). By default, it pulls the `latest` tag.
*   **`docker pull <image-name>:<version_or_tag>`:** Downloads a specific version or tag of an image. Tags can be numerical (e.g., `22.04`) or descriptive (e.g., `jammy`).

#### Pushing Images to Registries:

*   **`docker push <registry-url/image-name:tag>`:** Uploads an image to a Docker registry.
*   **Renaming Images (`docker tag`):** Before pushing to a specific private registry, you might need to rename (tag) your local image to include the registry's URL prefix.
    *   **Example:** `docker tag classify_spam:v1 docker.myprivateregistry.com/classify_spam:v1`
    *   Then: `docker push docker.myprivateregistry.com/classify_spam:v1`

#### Authenticating with Private Registries:

*   **`docker login <registry-url>`:** Used to authenticate with private Docker registries that require credentials. The URL provided must match the prefix used for image names.
    *   **Example:** `docker login dockerhub.myprivateregistry.com`

#### Exporting/Importing Images as Files:

*   **`docker save -o <filename.tar> <image-name:tag>`:** Exports a Docker image (or multiple images) as a `.tar` archive file. This is useful for sharing images with a small group of people without a registry.
    *   **Example:** `docker save -o spam_updated.tar spam:v2`
*   **`docker load --input <filename.tar>`:** Imports Docker images from a `.tar` archive file into your local Docker image cache.
    *   **Example:** `docker load --input spam_bob.tar`

#### Managing Local Images:

*   **`docker images`** or **`docker image ls`:** Lists all images currently stored on your local machine, including their tags, size, and ID.
*   **`docker rmi <image-id | image-name:tag>`** or **`docker image rm <image-id | image-name:tag>`:** Removes an image from local storage.
    *   **Important:** An image can only be deleted if no containers are based on it. Docker will issue an error and provide the IDs of the containers preventing the deletion. You must remove those containers first.
*   **`docker image prune`:** Removes "dangling" images. A dangling image is one that no longer has a name/tag because it was superseded (e.g., when rebuilding an image with the same name).
*   **`docker image prune -a`:** Removes *all* unused images, including dangling images and any other images not associated with a running container.

**Code Snippets:**

```shell
docker tag classify_spam:v1 docker.myprivateregistry.com/classify_spam:v1 # Tag local image for a remote repo
docker push docker.mycompany.com/spam_alice:v3 # Upload image to a remote repo (after tagging)
docker login docker.mycompany.com # Log in to a private registry
docker pull docker.mycompany.com/spam_alice:v3 # Pull image from a private repo

docker save -o spam_updated.tar spam:v2 # Export Docker image as a .tar archive
docker load --input spam_bob.tar # Load image from a .tar archive

docker pull hello-world # Download latest hello-world image
docker images # List local images
docker image rm hello-world # Delete a local image (if no containers are based on it)
docker container prune # Remove all stopped containers
docker image prune -a # Remove all unused images
```

### 4. Creating Custom Docker Images with Dockerfiles

**Dockerfiles** are text files that contain a series of instructions for building a Docker image. They act as the "recipe" or "blueprint" for your custom container environments. Docker executes instructions in a Dockerfile from top to bottom. By convention, the file should be named `Dockerfile`.

#### Basic Dockerfile Structure and Instructions:

*   **`FROM <base-image>:<tag>`:** The **first instruction** in every Dockerfile. It specifies the base image upon which your custom image will be built. You can use any existing image (e.g., `ubuntu`, `python:3.9-slim`, `postgres`).
    *   **Example:** `FROM ubuntu` or `FROM python:3.9-slim`
*   **Building an Image:**
    *   **`docker build <path-to-dockerfile-context>`:** Builds an image from a Dockerfile.
    *   The `.` (dot) often represents the current working directory, indicating that the Dockerfile is in the current folder.
    *   **Output:** The build process generates a unique `sha256` hash (Image ID) for the new image.
*   **`docker build -t <image-name>:<tag> <path-to-dockerfile-context>`:** Assigns a recognizable name and optional version (tag) to the newly built image.
    *   **Example:** `docker build -t my-python-app:v1 .`

#### Customizing Images with `RUN` Instruction:

*   **`RUN <shell-command>`:** Executes any valid shell command *during the image build process*. This is how you install software, update packages, or configure the environment inside your image.
    *   **Example:** To install Python on an Ubuntu base image:
        ```dockerfile
        FROM ubuntu
        RUN apt-get update           # Update package list (important before installing)
        RUN apt-get install -y python3 # Install Python 3. The -y flag confirms installation without user input.
        ```
    *   **Build Time:** `RUN` instructions extend the build time as Docker executes the specified commands.

#### Best Practices for `RUN` (Chaining Commands):

To keep images small, perform file downloads, unzips, and removals in a single `RUN` instruction. Intermediate files (like `.zip` archives) would otherwise be saved as layers in the image history, increasing its size even if removed in a later step.

*   **Chaining Commands:** Use `\` for line breaks (readability) and `&&` to execute commands sequentially.
    ```dockerfile
    FROM ubuntu
    RUN apt-get update && \
        apt-get install -y python3 && \
        curl -o file.zip <URL_TO_FILE> && \
        unzip file.zip && \
        rm file.zip
    ```
    This ensures that temporary files are deleted within the *same layer*, minimizing the final image size.

#### Adding Files with `COPY` Instruction:

*   **`COPY <source-path-on-host> <destination-path-in-container>`:** Copies files or directories from your local host machine (where `docker build` is run) into the Docker image.
    *   **Source Path:** Can be a file or a folder. If a folder, its entire contents (including sub-folders) are copied.
    *   **Destination Path:** If it ends with a `/`, the source will be copied into that directory; otherwise, if it's a filename, the source will be renamed to that filename.
    *   **Example:** `COPY ./pipeline.py /app/pipeline.py` (copies `pipeline.py` from current host directory to `/app/pipeline.py` in container).
    *   **Important:** You cannot copy files from a parent directory of the Dockerfile's context (the directory where `docker build` is executed).

*   **`ADD` Instruction:** While `ADD` can also copy files and handle archives automatically, `COPY` combined with `RUN` for specific download/unzip/cleanup tasks is generally preferred for clarity and image size control.

**Code Snippets:**

```bash
# Create a Dockerfile
touch Dockerfile
nano Dockerfile # or use any text editor

# Example Dockerfile content:
# FROM ubuntu
# RUN apt-get update
# RUN apt-get install -y python3
# COPY ./app_code /app
# WORKDIR /app
# CMD ["python3", "main.py"]

# Build the Dockerfile and name it python_image
docker build -t python_image .

# Copy a specific file
COPY ./pipeline.py ./app/pipeline.py

# Copy an entire folder
COPY ./app_code /app/```

### 5. Setting Default Commands with `CMD`

The `CMD` instruction defines the default command that will be executed when a container is started from your image.

*   **`CMD ["executable", "param1", "param2"]` (Exec Form - Preferred):** Specifies the command as an array, where the first element is the executable and subsequent elements are arguments.
*   **`CMD command param1 param2` (Shell Form):** Executes the command directly in a shell.
*   **Behavior:** The `CMD` instruction is *not* executed during `docker build`. It only runs when `docker run` is called without specifying an overriding command.
*   **Image Size/Build Time:** `CMD` does not increase image size or build time.
*   **Multiple `CMD` Instructions:** Only the *last* `CMD` instruction in a Dockerfile will take effect.
*   **Purpose:** For specific-use images, `CMD` should start the core application (e.g., a Python script, a database server). For general-purpose images (like an Ubuntu base image), `CMD` might open a shell (e.g., `CMD ["bash"]`). The container stops when the `CMD` process exits.

#### Overriding `CMD` at Runtime:

*   **`docker run <image-name> <new-command>`:** You can override the `CMD` instruction defined in the Dockerfile by providing a command as a second argument to `docker run`.
    *   **Example:** If an image has `CMD ["python3", "app.py"]`, `docker run my-app-image bash` would override it and start a bash shell instead.
    *   Often, when overriding, you'll use `-it` to interact with the new command (e.g., `docker run -it my-ubuntu-image bash`).

**Code Snippet (Dockerfile):**

```dockerfile
# Inside a Dockerfile
CMD ["python3"] # Sets python3 as the default command when container starts
```

### 6. Optimizing Docker Image Builds with Layers and Caching

Docker images are composed of **layers**, which correspond to individual instructions in the Dockerfile. Understanding layers and caching is crucial for efficient image building.

#### How Layers Work:

*   When a Dockerfile instruction is executed during a `docker build`, the changes it makes to the file system are saved as a distinct **layer** in the image.
*   An image can be viewed as a stack of these consecutive file system changes.
*   The build output clearly shows Docker processing each "step" (layer) (e.g., "Step X/Y").
*   Metadata (like the `CMD` instruction) is also part of the image but doesn't create a file system layer.

#### Image Layer Caching:

*   **Speeding Up Builds:** Docker significantly speeds up subsequent builds of the *same* Dockerfile by using a build cache. If an instruction (and all preceding instructions) is identical to a previously built version, Docker will reuse the cached layer instead of re-executing the instruction. This is indicated by "(cached)" in the build output.
*   **Cache Invalidation:** The cache is invalidated if an instruction or any preceding instruction changes. Once a layer's cache is invalidated, all subsequent layers must also be rebuilt.

#### Importance of Understanding Caching:

1.  **Unintended Stale Images:** If you change a Dockerfile instruction (e.g., `apt-get update`) but Docker uses a cached layer, your image might not include the latest software updates, as Docker assumes identical instructions yield identical results.
2.  **Efficient Dockerfile Writing:**
    *   **Order of Instructions:** Arrange instructions from *least frequently changing* to *most frequently changing*.
    *   **Example:** Install packages (`RUN apt-get install`) early in the Dockerfile, as these dependencies typically change less often. Copy application code (`COPY . /app`) later, as code changes frequently during development. This maximizes the reuse of cached layers, reducing rebuild times significantly when only application code changes.

**Code Snippet (Optimized Dockerfile Example):**

```dockerfile
# Base image - rarely changes
FROM ubuntu:24.04

# Install system packages - changes less frequently
RUN apt-get update && \
    apt-get install -y python3

# Copy application requirements - changes less frequently than main code
COPY /app/requirements.txt /app/requirements.txt
RUN pip install -r /app/requirements.txt

# Copy application code - changes frequently
COPY /app/pipeline.py /app/pipeline.py
# Set working directory and CMD for the application
WORKDIR /app
CMD ["python3", "pipeline.py"]
```
*(Note: In the example, `COPY /app/requirements.txt /app/requirements.txt` should copy to a file, not a directory. Changed to `requirements.txt`.)*

### 7. Influencing Instructions: `WORKDIR` and `USER`

Some Dockerfile instructions directly influence how subsequent instructions behave, rather than just affecting the file system.

#### `WORKDIR` Instruction:

*   **Purpose:** Changes the default working directory inside the image for all subsequent instructions (`RUN`, `CMD`, `COPY`, `ENTRYPOINT`). This avoids the need for full paths and improves readability.
*   **Syntax:** `WORKDIR <path-in-container>`
*   **Example:**
    ```dockerfile
    FROM ubuntu:22.04
    WORKDIR /home/app # Sets /home/app as the working directory
    RUN mkdir projects/pipeline_final # Creates /home/app/projects/pipeline_final
    COPY . ./projects/pipeline_final # Copies from host CWD to /home/app/projects/pipeline_final
    ```
    (Note: The original example `COPY home/repl/projects projects/pipeline_final` was trying to copy from *inside* the image, which `COPY` doesn't do; `COPY` takes from host context. Adjusted example to copy from host CWD (`.`) to a relative path in container).
*   **Effect on `CMD` and `ENTRYPOINT`:** The commands specified by `CMD` or `ENTRYPOINT` will also execute within the directory set by the last `WORKDIR` instruction. If a user overrides `CMD`, their custom command will also run in this directory.

#### `USER` Instruction:

*   **Purpose:** Changes the user under which subsequent Dockerfile instructions (and the default command for containers started from the image) are executed. This is a crucial security best practice.
*   **Background:** In Linux, permissions are tied to users. The `root` user has all permissions, which is unsafe for running applications. Base images like `ubuntu` often default to the `root` user.
*   **Best Practice:**
    1.  Use `root` to install necessary software and create new, less-privileged users.
    2.  Switch to one of these less-privileged users using the `USER` instruction before running application code or defining the `CMD`.
*   **Syntax:** `USER <username_or_uid>`
*   **Example:**
    ```dockerfile
    FROM ubuntu:22.04
    RUN useradd -m repl # Create a new user named 'repl' (with home directory)
    USER repl           # Switch to the 'repl' user for subsequent instructions
    WORKDIR /home/repl/app # Set working directory for 'repl' user
    # Any subsequent RUN, COPY, CMD, ENTRYPOINT instructions will run as 'repl'
    ```
*   **Effect on Container Runtime:** The user specified by the last `USER` instruction in the Dockerfile will be the user running inside any containers started from that image. This prevents malicious code from having root access.

### 8. Using Variables in Dockerfiles (`ARG` and `ENV`)

Variables enhance Dockerfile readability, maintainability, and flexibility.

#### `ARG` Instruction (Build-Time Variables):

*   **Purpose:** Defines variables that are *only accessible during the image build process*. They are not available inside the container at runtime.
*   **Syntax:** `ARG <variable_name>=<default_value>`
*   **Usage:** Reference with `$variable_name` or `${variable_name}`.
*   **Typical Use Cases:** Defining version numbers (e.g., `ARG PYTHON_VERSION=3.9`), project paths, or build-specific parameters.
*   **Overriding at Build Time:** The default value can be overridden using the `--build-arg` flag with `docker build`.
    *   **Example:** `docker build --build-arg PROJECT_FOLDER=/tmp/my_project .`
*   **Security Note:** `ARG` variables are visible in the build history (`docker history`) and are **not suitable for secrets**.

#### `ENV` Instruction (Runtime Environment Variables):

*   **Purpose:** Defines environment variables that are *accessible both during the image build and inside the container at runtime*.
*   **Syntax:** `ENV <variable_name>=<value>`
*   **Usage:** Reference with `$variable_name` or `${variable_name}`.
*   **Typical Use Cases:** Configuring application behavior at runtime (e.g., `ENV APP_MODE=production`), setting database connection details (though not for secrets directly).
*   **Overriding at Runtime:** `ENV` variables cannot be overridden during the *build* process using `--build-arg`. However, they *can* be overridden when starting a container using the `--env` (or `-e`) flag with `docker run`.
    *   **Example:** `docker run -e DATABASE_URL=new_db_address my-app-image`
*   **Security Note:** `ENV` variables are visible in the image layers (`docker history`) and are **not secure for sensitive information like passwords**. They can also be found in the container's shell history.

**Security Best Practice for Secrets:**
Avoid embedding secrets directly in Dockerfiles using `ARG` or `ENV`. Advanced techniques (e.g., Docker secrets, Kubernetes secrets, external secret management services) should be used to handle sensitive information securely. Any secrets used during the build process will be permanently embedded in the image layers if not carefully managed (e.g., removed in the same `RUN` command).

**Code Snippets:**

```bash
# Change arguments at build time
docker build --build-arg PROJECT_FOLDER=/custom_path .

# Add environment variables at runtime
docker run --env APP_ENV=development my-app-image
```

### 9. Enhancing Container Security: Non-Root Users

A critical security measure in Dockerfiles is to avoid running applications as the `root` user inside the container.

*   **Problem:** By default, many base images run as `root`. If a containerized application runs as `root`, any exploit against that application would grant the attacker full root privileges within the container, and potentially (though less commonly now due to better isolation) on the host system.
*   **Solution:** After necessary installations and configurations (which often require `root` privileges), explicitly switch to a less-privileged user using the `USER` instruction *before* defining the `CMD` or `ENTRYPOINT` that starts your application.
    *   **Example:**
        ```dockerfile
        FROM ubuntu:22.04
        RUN apt-get update && apt-get install -y some-package
        # Create a new user with limited privileges
        RUN useradd -m appuser
        USER appuser # Switch to the less-privileged user
        WORKDIR /home/appuser/app
        COPY . /home/appuser/app
        CMD ["python3", "my_app.py"]
        ```
    *   This ensures that if the application or pipeline is compromised, the malicious code will not have root access within the container, significantly reducing the potential damage.